{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries/modules\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set dataframe visualization row and column limts\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 - Intial Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv as pandas df\n",
    "df1 = pd.read_csv(\"cleaner_merged_data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df with just ids\n",
    "df2 = df1[[\"steam_appid\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column with boolean with True for when df1 name_x is not null\n",
    "df2.loc[:,\"has_name\"]  = df1.loc[:,\"name_x\"].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the age column, create a new one,  deleting the + singns at the end of some of the strings\n",
    "df2.loc[:, \"required_age\"]  = df1.loc[:, \"required_age\"].str.replace(\"+\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn strings into int\n",
    "df2.loc[:, \"required_age\"]  = df2.loc[:, \"required_age\"].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the is free column\n",
    "df2.loc[:, \"is_free\"]  = df1.loc[:, \"is_free\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column with boolean for when this column is not null\n",
    "df2.loc[:,\"has_about_game\"]  = df1.loc[:,\"about_the_game\"].notna()\n",
    "df2.loc[:,\"has_detailed_description\"]  = df1.loc[:,\"detailed_description\"].notna()\n",
    "df2.loc[:,\"has_short_description\"]  = df1.loc[:,\"short_description\"].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of full audio text in various languages\n",
    "FullAudio = [\"(all with full audio support)\", \"languages with full audio support\", \"idiomas con localización de audio\", \"med fuld lydunderstøttelse\", \"ęzyki z pełnym udźwiękowieniem\",\n",
    "                             \"- スペインフル音声対応言語\", \"フル音声対応言語\", \"озвучивание доступно на этих языках\", \"idiomas com suporte total de áudio\", \"Langues avec support audio complet\", \"具有完全音频支持的语言\", \n",
    "                             \"lingue con supporto audio completo\", \"Sprachen mit voller Audiounterstützung\", \"bahasa dengan dukungan audio penuh\", \"(text only)\", \"(full audio)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove html tangs and text between brackets\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    clean_text = soup.get_text()\n",
    "    clean_text = html.unescape(clean_text)\n",
    "    clean_text = re.sub(r'<[^<]+?>', '', clean_text)\n",
    "    clean_text = re.sub(r'\\[.*?\\]', '', clean_text)\n",
    "    return clean_text\n",
    "\n",
    "#function to further clean text by removing the full audio text and asterisks\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        clean = remove_html_tags(text)\n",
    "        cleaner = clean.replace(\"*\", \"\")\n",
    "        for i in FullAudio:\n",
    "            if i in cleaner:\n",
    "                cleaner = cleaner.replace(i, \"\")\n",
    "        text = cleaner\n",
    "    else: \n",
    "        text = text \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply clean text function to languages column\n",
    "df1[\"supported_languages\"] = df1[\"supported_languages\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all unique language values\n",
    "all_languages = set()\n",
    "for languages_str in df1['supported_languages']:\n",
    "    if isinstance(languages_str, str):\n",
    "        languages = languages_str.split(', ')\n",
    "    for lang in languages:\n",
    "        all_languages.add(lang.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put them in list and print\n",
    "languages_list = list(all_languages)\n",
    "for index, language in enumerate(languages_list):\n",
    "    print(index, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary mappinng all variations of all unique languages\n",
    "languages = {}\n",
    "languages[\"Yoruba\"] = [\"Yoruba\"]\n",
    "languages[\"Russian\"] = [\"Ruso\", \"Russisksprog\", \"Russian\", \"Bhs. Rusia\", \"ロシア語\", \"Russisk\", \"Russisch\", \"русский\",\"俄语\", \"Rosyjski\", \"Russe\", \"Russo\"]\n",
    "languages[\"Odia\"] = [\"Odia\"]\n",
    "languages[\"Chinese\"] = [\"Chino simplificado\",\"繁体中文\",\"Chiński uproszczony\",\"Simplified Chinese\",\"Cinese tradizionale\",\"Chiński tradycyjny\",\"Chinois traditionnel\",\"Chinês tradicional\",\"Traditional Chinese\",\"Bhs. Tionghoa Sederhana\",\"Forenklet kinesisk\",\"简体中文\",\"Chinesisch (vereinfacht)\",\"китайский (упр.)\",\"Chino tradicional\", \"Chinesisch (traditionell)\", \"китайский (трад.)\", \"中国語（簡体字)\", \"Chinês simplificado\", \"Chinois simplifié\", \"Bhs. Tionghoa Tradisional\"]\n",
    "languages[\"Danish\"] = [\"Danish\",\"Danese\", \"датский\"]\n",
    "languages[\"Punjabi\"] = [\"Punjabi (Gurmukhi)\", \"Punjabi (Shahmukhi)\"]\n",
    "languages[\"Romanian\"] = [\"Romanian\", \"румынский\"]\n",
    "languages[\"Polish\"] = [\"Polacco\", \"Polish\", \"Polonais\", \"波兰语\", \"Polnisch\", \"Polaco\", \"Polski\", \"Bhs. Polandia\", \"Polsk\", \"польский\"]\n",
    "languages[\"Korean\"] = [\"Bhs. Korea\", \"Koreanisch\", \"Korean\", \"корейский\", \"Coreano\", \"韩语\", \"韓国語\", \"Koreansk\",\"Koreański\", \"Coréen\"]\n",
    "languages[\"English\"] = [\"Angielski\", \"Engelsk\", \"英語\", \"Inglês\", \"Inglese\", \"Bhs. Inggris\", \"английский\", \"Englisch\", \"Inglés\", \"英语\", \"Anglais\", \"English\"]\n",
    "languages[\"Marathi\"] = [\"Marathi\"]\n",
    "languages[\"Norwegian\"] = [\"Norwegian\", \"норвежский\"]\n",
    "languages[\"Turkish\"] = [\"Turco\", \"Bhs. Turki\", \"Tureckij\", \"Turkish\", \"турецкий\", \"Turkmen\"]\n",
    "languages[\"Albanian\"]= [\"Albanian\"]\n",
    "languages[\"French\"] = [\"Bhs. Prancis\",\"Francese\", \"Fransk\", \"French\", \"Francês\", \"Francés\", \"法语\", \"Francuski\", \"フランス語\", \"Français\",\"Französisch\", \"французский\"]\n",
    "languages[\"Czech\"] = [\"Czech\", \"Tcheco\", \"чешский\", \"捷克语\", \"Tschechisch\", \"Bhs. Ceko\"]\n",
    "languages[\"Italian\"] =[\"Włoski\", \"Italienisch\", \"イタリア語\", \"Italian\", \"意大利语\", \"итальянский\", \"Italien\", \"Italiano\", \"Italiensk\", \"Bhs. Italia\"]\n",
    "languages[\"Slovak\"]=[\"Slovak\", \"#lang_slovakian\"]\n",
    "languages[\"Zulu\"]=[\"Zulu\"]\n",
    "languages[\"Kyrgyz\"]=[\"Kyrgyz\"]\n",
    "languages[\"Hungarian\"]=[\"Bhs. Hungaria\", \"венгерский\", \"Hungarian\",\"Ungarisch\"]\n",
    "languages[\"Sotho\"]=[\"Sotho\"]\n",
    "languages[\"Spanish\"]=[\"西班牙语 - 西班牙\",\"Spanish - Spain\",\"Spagnolo - Spagna\",\"Hiszpański latynoamerykański\",\"Espagnol - Amérique latine\",\"スペイン語\",\"スペイン語 - スペイン\", \"Hiszpański latynoamerykańskij\", \"Espagnol - Espagne\",\"Spagnolo - America Latina\",\"Spanisch – Spanien\",\"Hiszpański\", \"Español de España\", \"Espanhol (Espanha)\", \"Bhs. Spanyol - Amerika Latin\", \"Bhs. Spanyol - Spanyol\", \"Spansk – Spanien\", \"испанский Лат. Ам.\", \"Espanhol (América Latina)\", \"испанский\", \"Spanish - Latin America\"]\n",
    "languages[\"Macedonian\"]=[\"Macedonian\"]\n",
    "languages[\"German\"]=[\"Niemiecki\",\"German\", \"Tysk\", \"Alemão\", \"Alemán\", \"Tedesco\", \"Bhs. Jerman\", \"German;\", \"ドイツ語\", \"德语\", \"Allemand\", \"немецкий\", \"Deutsch\"]\n",
    "languages[\"Scots\"]=[\"Scots\"]\n",
    "languages[\"Slovenian\"]=[\"Slovenian\"]\n",
    "languages[\"Uyghur\"]=[\"Uyghur\"]\n",
    "languages[\"Thai\"]=[\"Bhs. Thai\", \"Thai\"]\n",
    "languages[\"Indonesian\"]=[\"Indonésio\", \"Indonezyjski\", \"Indonesian\"]\n",
    "languages[\"Arabic\"]=[\"Bhs. Arab\", \"Árabe\",\"阿拉伯语\", \"Arabo\", \"Arabic\", \"Arabski\"]\n",
    "languages[\"Tamil\"]=[\"Tamil\"]\n",
    "languages[\"Japanese\"]=[\"Japonés\",\"Bhs. Jepang\", \"японский\", \"日语\", \"Japanese\", \"日本語\", \"Japansk\", \"Japonais\", \"Giapponese\", \"Japonês\", \"Japoński\", \"Japanisch\"]\n",
    "languages[\"Lithuanian\"]=[\"Lithuanian\"]\n",
    "languages[\"Assamese\"]=[\"Assamese\"]\n",
    "languages[\"Portuguese\"]=[\"Portugisisk – Brasilien\",\"Português (Brasil)\",\"ポルトガル語－ブラジル\",\"Portugalski brazylijski\",\"Portugais du Brésil\",\"Brasilianisches Portugiesisch\",\"бр. португальский\",\"Portuguese - Portugal\", \"Portoghese - Brasile\", \"Portugués de Portugal\", \"Portugués de Brasil\", \"Portuguese - Brazil\", \"Portugalski\", \"португальский\", \"葡萄牙语 - 巴西\", \"Bhs. Portugis - Brasil\"]\n",
    "languages[\"Telugu\"]=[\"Telugu\"]\n",
    "languages[\"Finnish\"]=[\"Finnish\",\"финский\"]\n",
    "languages[\"Cherokee\"]=[\"Cherokee\"]\n",
    "languages[\"Ukrainian\"]=[\"Ukrainian\", \"украинский\", \"Bhs. Ukraina\"]\n",
    "languages[\"Swahili\"]=[\"Swahili\"]\n",
    "languages[\"Tswana\"]=[\"Tswana\"]\n",
    "languages[\"Kinyarwanda\"]=[\"Kinyarwanda\"]\n",
    "languages[\"Tatar\"]=[\"Tatar\"]\n",
    "languages[\"Mongolian\"]=[\"Mongolian\"]\n",
    "languages[\"Sinhala\"]=[\"Sinhala\"]\n",
    "languages[\"Hausa\"]=[\"Hausa\"]\n",
    "languages[\"Maori\"]=[\"Maori\"]\n",
    "languages[\"Galician\"]=[\"Galician\"]\n",
    "languages[\"Estonian\"]=[\"Estonian\"]\n",
    "languages[\"Bosnian\"]=[\"Bosnian\"]\n",
    "languages[\"Tigrinya\"]=[\"Tigrinya\"]\n",
    "languages[\"Nepali\"]=[\"Nepali\"]\n",
    "languages[\"Catalan\"]=[\"Catalan\", \"Valencian\"]\n",
    "languages[\"Hebrew\"]=[\"Hebrew\"]\n",
    "languages[\"Kannada\"]=[\"Kannada\"]\n",
    "languages[\"Sindhi\"]=[\"Sindhi\"]\n",
    "languages[\"Persian\"]=[\"Persa\", \"Persian\", \"Tajik\", \"Dari\"]\n",
    "languages[\"Icelandic\"]=[\"Icelandic\"]\n",
    "languages[\"Bengali\"]=[\"Bangla\"]\n",
    "languages[\"Quechua\"]=[\"Quechua\"]\n",
    "languages[\"Azerbaijani\"]=[\"Azerbaijani\"]\n",
    "languages[\"Serbian\"]=[\"Serbian\"]\n",
    "languages[\"Uzbek\"]=[\"Uzbek\"]\n",
    "languages[\"Dutch\"]=[\"нидерландский\", \"Dutch\", \"Niederländisch\", \"荷兰语\", \"Olandese\"]\n",
    "languages[\"Kazakh\"]=[\"Kazakh\"]\n",
    "languages[\"Swedish\"]=[\"шведский\", \"Svensksprog\", \"Swedish\"]\n",
    "languages[\"Malayalam\"]=[\"Malayalam\"]\n",
    "languages[\"Maltese\"]=[\"Maltese\"]\n",
    "languages[\"Wolof\"]=[\"Wolof\"]\n",
    "languages[\"Afrikaans\"]=[\"Afrikaans\"]\n",
    "languages[\"Basque\"]=[\"Basque\"]\n",
    "languages[\"Latvian\"]=[\"Latvian\"]\n",
    "languages[\"Armeian\"]=[\"Armenian\"]\n",
    "languages[\"Irish\"]=[\"Irish\"]\n",
    "languages[\"Belarusian\"]=[\"Belarusian\"]\n",
    "languages[\"Vietnamese\"]=[\"Vietnamese\", \"Vietnamita\"]\n",
    "languages[\"Konkani\"]=[\"Konkani\"]\n",
    "languages[\"Hindi\"]=[\"Hindi\"]\n",
    "languages[\"Bulgarian\"]=[\"Bulgarian\", \"болгарский\"]\n",
    "languages[\"Georgian\"]=[\"Georgian\"]\n",
    "languages[\"K'iche'\"]=[\"K'iche'\"]\n",
    "languages[\"Amharic\"]=[\"Amharic\"]\n",
    "languages[\"Malay\"]=[\"Malay\"]\n",
    "languages[\"Khmer\"]=[\"Khmer\"]\n",
    "languages[\"Croatian\"]=[\"Croatian\"]\n",
    "languages[\"Sorani\"]=[\"Sorani\"]\n",
    "languages[\"Greek\"]=[\"Greek\", \"греческий\"]\n",
    "languages[\"Welsh\"]=[\"Welsh\"]\n",
    "languages[\"Luxembourgish\"]=[\"Luxembourgish\"]\n",
    "languages[\"Xhosa\"]=[\"Xhosa\"]\n",
    "languages[\"Filipino\"]=[\"Filipino\"]\n",
    "languages[\"Igbo\"]=[\"Igbo\"]\n",
    "languages[\"Gujarati\"]=[\"Gujarati\"]\n",
    "languages[\"Urdu\"]=[\"Urdu\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create columns for each language with false as default value\n",
    "for i in languages.keys():\n",
    "    df2[i]= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for adding true to the boolean columns if the game supports that languege\n",
    "for index, row in df1.iterrows():\n",
    "    languages_str = row[\"supported_languages\"]\n",
    "    if isinstance(languages_str, str):\n",
    "        languages_list = languages_str.split(', ')\n",
    "        for i in languages_list:\n",
    "            i = i.strip()\n",
    "            for key, value in languages.items():\n",
    "                if any(lang in languages_list for lang in value):\n",
    "                    df2.loc[index, key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column with boolean with True for when this column is not null\n",
    "df2.loc[:,\"has_headerImage\"]  = df1.loc[:,\"header_image\"].notna()\n",
    "df2.loc[:,\"has_capsuleImage\"]  = df1.loc[:,\"capsule_image\"].notna()\n",
    "df2.loc[:,\"has_capsuleImagev5\"]  = df1.loc[:,\"capsule_imagev5\"].notna()\n",
    "df2.loc[:,\"has_website\"]  = df1.loc[:,\"website\"].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply clean text function to pc requirements\n",
    "df1[\"pc_requirements\"] = df1[\"pc_requirements\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of pc requiremnet levels with common specs\n",
    "processor = {\"Low\": [\"i3\", \"ryzen 3\", \"athlon\", \"dual-core\", \"dual core\"],\n",
    "              \"Medium\": [\"i5\", \"i7\", \"ryzen 5\", \"ryzen 7\", \"quad-core\", \"quad core\"], \n",
    "              'High': [\"i9\", \"ryzen 9\", \"threadripper\", \"hexa-core\", \"hexa core\",\"octa-core\", \"octa core\"]}\n",
    "memory = {\"Low\": [\"memory: 1gb\", \"memory: 1 gb\", \"memory: 1gigabytes\", \"memory: 1 gigabytes\", \"memory: 2gb\", \"memory: 2 gb\", \"memory: 2gigabytes\", \"memory: 2 gigabytes\", \"memory: 3gb\", \"memory: 3 gb\", \"memory: 3gigabytes\", \"memory: 3 gigabytes\",\"memory: 4gb\", \"memory: 4 gb\", \"memory: 4gigabytes\", \"memory: 4 gigabytes\", \"memory: 5gb\", \"memory: 5 gb\", \"memory: 5gigabytes\", \"memory: 5 gigabytes\", \"memory: 6gb\", \"memory: 6 gb\", \"memory: 6gigabytes\", \"memory: 6 gigabytes\"], \n",
    "          \"Medium\": [\"memory: 8gb\", \"memory: 8 gb\", \"memory: 8gigabytes\", \"memory: 8 gigabytes\", \"memory: 10gb\", \"memory: 10 gb\", \"memory: 10gigabytes\", \"memory: 10 gigabytes\", \"memory: 12gb\", \"memory: 12 gb\", \"memory: 12gigabytes\", \"memory: 12 gigabytes\", \"memory: 14gb\", \"memory: 14 gb\", \"memory: 14gigabytes\", \"memory: 14 gigabytes\"],\n",
    "          \"High\": [\"memory: 16gb\", \"memory: 16 gb\", \"memory: 16gigabytes\", \"memory: 16 gigabytes\", \"memory: 32gb\", \"memory: 32 gb\", \"memory: 32gigabytes\", \"memory: 32 gigabytes\", \"memory: 64gb\", \"memory: 64 gb\", \"memory: 64gigabytes\", \"memory: 64 gigabytes\"]}\n",
    "graphics = {\"Low\": [\"gt 10\", \"gt10\", \"rx 4\", \"rx4\", \"intel hd\", \"intelhd\", \"directx\", \"shader\", \"graphics: 2gb\", \"graphics: 2 gb\", \"graphics: 2gigabytes\", \"graphics: 2 gigabytes\", \"graphics: 4gb\", \"graphics: 4 gb\", \"graphics: 4gigabytes\", \"graphics: 4 gigabytes\"],\n",
    "            \"Medium\": [\"gtx 16\", \"gtx16\", \"rtx 20\", \"rtx20\", \"rx5\" \"rx 5\", \"graphics: 6gb\", \"graphics: 6 gb\", \"graphics: 6gigabytes\", \"graphics: 6 gigabytes\", \"graphics: 8gb\", \"graphics: 8 gb\", \"graphics: 8gigabytes\", \"graphics: 8 gigabytes\"],\n",
    "            \"High\": [\"rtx30\", \"rtx 30\", \"rtx40\", \"rtx 40\", \"rx 6\", \"rx6\", \"rx7\", \"rx 7\", \"graphics: 10gb\", \"graphics: 10 gb\", \"graphics: 10gigabytes\", \"graphics: 10 gigabytes\", \"graphics: 12gb\", \"graphics: 12 gb\", \"graphics: 12gigabytes\", \"graphics: 12 gigabytes\", \"graphics: 14gb\", \"graphics: 14 gb\", \"graphics: 14gigabytes\", \"graphics: 14 gigabytes\", \"graphics: 16gb\", \"graphics: 16 gb\", \"graphics: 16gigabytes\", \"graphics: 16 gigabytes\"]}\n",
    "storage = {\"Low\": [\"hdd\"],\n",
    "           \"Medium\": [\"ssd 500\", \"ssd: 500\", \"ssd500\"],\n",
    "           \"High\": [\"ssd 1t\", \"ssd1t\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new colums for separate pc reqs\n",
    "df2[\"Processor\"] = None\n",
    "df2[\"Memory\"] = None\n",
    "df2[\"Graphics\"] = None\n",
    "df2[\"Storage\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the row contents for the pc requirements column and updating the processor, memory, grapgics, and storage column\n",
    "#based on the presence of the dictionary values \n",
    "for index, row in df1.iterrows():\n",
    "    pc_reqs_str = row[\"pc_requirements\"]\n",
    "    if isinstance(pc_reqs_str, str):\n",
    "        for key, value in processor.items():\n",
    "            if any(req in pc_reqs_str for req in value):\n",
    "                df2.loc[index, \"Processor\"] = key\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    pc_reqs_str = row[\"pc_requirements\"]\n",
    "    if isinstance(pc_reqs_str, str):\n",
    "        for key, value in memory.items():\n",
    "            if any(req in pc_reqs_str for req in value):\n",
    "                df2.loc[index, \"Memory\"] = key\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    pc_reqs_str = row[\"pc_requirements\"]\n",
    "    if isinstance(pc_reqs_str, str):\n",
    "        for key, value in graphics.items():\n",
    "            if any(req in pc_reqs_str for req in value):\n",
    "                df2.loc[index, \"Graphics\"] = key\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    pc_reqs_str = row[\"pc_requirements\"]\n",
    "    if isinstance(pc_reqs_str, str):\n",
    "        for key, value in storage.items():\n",
    "            if any(req in pc_reqs_str for req in value):\n",
    "                df2.loc[index, \"Storage\"] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply clean text\n",
    "df1[\"developers\"] = df1[\"developers\"].apply(clean_text)\n",
    "df1[\"publishers\"] = df1[\"publishers\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to apply literal eval with error handling\n",
    "def handle_literal_eval(x):\n",
    "    try:\n",
    "        return literal_eval(x)\n",
    "    except (SyntaxError, ValueError):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply literal eval to columns\n",
    "df1[\"publishers\"] = df1[\"publishers\"].apply(lambda x: handle_literal_eval(x))\n",
    "df1[\"developers\"] = df1[\"developers\"].apply(lambda x: handle_literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only first in list \n",
    "for index, row in df1.iterrows():\n",
    "    devs_list = row[\"developers\"]\n",
    "    if isinstance(devs_list, list):\n",
    "        df2.loc[index, \"developers\"] = devs_list[0]\n",
    "for index, row in df1.iterrows():\n",
    "    devs_list = row[\"publishers\"]\n",
    "    if isinstance(devs_list, list):\n",
    "        df2.loc[index, \"publishers\"] = devs_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appy literal eval\n",
    "df1[\"platforms\"] = df1[\"platforms\"].apply(lambda x: handle_literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new colums for each platfom supported based on the key-val pairs in the original platform dictionary\n",
    "for index, row in df1.iterrows():\n",
    "    plat_dict = row[\"platforms\"]\n",
    "    if isinstance(plat_dict, dict):\n",
    "        for key, value in plat_dict.items():\n",
    "            df2.loc[index, key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make boolean type\n",
    "df2[\"windows\"] = df2[\"windows\"].astype(bool)\n",
    "df2[\"mac\"] = df2[\"mac\"].astype(bool)\n",
    "df2[\"linux\"] = df2[\"linux\"].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column with boolean with True for when this column is not null\n",
    "df2.loc[:,\"has_metacritic_score\"]  = df1.loc[:,\"metacritic\"].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply literal_eval\n",
    "df1[\"categories\"] = df1[\"categories\"].apply(lambda x: handle_literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set of unique category ids\n",
    "all_catids = set()\n",
    "for cat_list in df1['categories']:\n",
    "    if isinstance(cat_list, list):\n",
    "        for cat_dict in cat_list:\n",
    "            if isinstance(cat_dict, dict):\n",
    "                cat_id = cat_dict.get(\"id\")\n",
    "                all_catids.add(cat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make categories dictionary\n",
    "all_categories_dict = {}\n",
    "unique_names = set()\n",
    "for cat_id in all_catids:\n",
    "    all_categories_dict[cat_id] = []\n",
    "    for cat_list in df1['categories']:\n",
    "        if isinstance(cat_list, list):\n",
    "            for cat_dict in cat_list:\n",
    "                if isinstance(cat_dict, dict):\n",
    "                    if cat_dict.get(\"id\") == cat_id:\n",
    "                        cat_name = cat_dict.get(\"description\")\n",
    "                        cat_name = cat_name.lower()\n",
    "                        if cat_name not in unique_names:\n",
    "                            all_categories_dict[cat_id].append(cat_name)\n",
    "                            unique_names.add(cat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a new version using the english names as keys and the ids as values\n",
    "new_cat_dict = {\n",
    "    \"multiplayer\": [1],\n",
    "    \"singlepalyer\": [2],\n",
    "    \"mods\": [6, 19],\n",
    "    \"valveAntiCheat\": [8],\n",
    "    \"coOp\": [9, 38],\n",
    "    \"captions\": [13],\n",
    "    \"commentary\":[14],\n",
    "    \"stats\":[15],\n",
    "    \"sourceSDK\": [16],\n",
    "    \"levelEditor\": [17],\n",
    "    \"partialControllerSupport\":[18],\n",
    "    \"mmo\": [20],\n",
    "    \"steamAchievements\": [22],\n",
    "    \"steamCloud\": [23],\n",
    "    \"sharedScreen\": [24, 37, 39],\n",
    "    \"steamLeaderboards\": [25],\n",
    "    \"crossPlatformMultiplayer\": [27],\n",
    "    \"fullControlerSupport\": [28],\n",
    "    \"steamTradingCards\": [29],\n",
    "    \"steamWorkshop\": [30, 51],\n",
    "    \"vrSupport\": [31, 53],\n",
    "    \"steamTurnNotifications\": [32],\n",
    "    \"inAppPurchases\": [35],\n",
    "    \"steamVRCollectibles\": [40],\n",
    "    \"remotePlay\": [41, 42, 43],\n",
    "    \"remotePlayTogether\": [44],\n",
    "    \"lanPvP\": [47],\n",
    "    \"lanCoOp\": [48],\n",
    "    \"pVp\": [49],\n",
    "    \"trackedControllerSupport\": [52],\n",
    "    \"vrOnly\": [54],\n",
    "    \"hdrAvailable\": [61],\n",
    "    \"familySharing\": [62]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create columns for each category key \n",
    "for key in new_cat_dict.keys():\n",
    "    df2[key] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update value for columns depending on whther the id for that category is present for that row\n",
    "for index, row in df1.iterrows():\n",
    "    cat_list = row[\"categories\"]\n",
    "    if isinstance(cat_list, list):\n",
    "        for cat_dict in cat_list:\n",
    "            if isinstance(cat_dict, dict):\n",
    "                cat_id = cat_dict.get(\"id\")\n",
    "                for key, value in new_cat_dict.items():\n",
    "                   if cat_id in value:\n",
    "                        df2.loc[index, key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply literal eval \n",
    "df1[\"genres\"] = df1[\"genres\"].apply(lambda x: handle_literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set of unique ids\n",
    "all_genids = set()\n",
    "for gen_list in df1['genres']:\n",
    "    if isinstance(gen_list, list):\n",
    "        for gen_dict in gen_list:\n",
    "            if isinstance(gen_dict, dict):\n",
    "                gen_id = gen_dict.get(\"id\")\n",
    "                all_genids.add(gen_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dictionary\n",
    "all_genres_dict = {}\n",
    "unique_gen_names = set()\n",
    "for gen_id in all_genids:\n",
    "    all_genres_dict[gen_id] = []\n",
    "    for gen_list in df1['genres']:\n",
    "        if isinstance(gen_list, list):\n",
    "            for gen_dict in gen_list:\n",
    "                if isinstance(gen_dict, dict):\n",
    "                    if gen_dict.get(\"id\") == gen_id:\n",
    "                        gen_name = gen_dict.get(\"description\")\n",
    "                        gen_name = gen_name.lower()\n",
    "                        if gen_name not in unique_gen_names:\n",
    "                            all_genres_dict[gen_id].append(gen_name)\n",
    "                            unique_gen_names.add(gen_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a new version using the english names as keys and the ids as values\n",
    "new_genres_dict= {\n",
    "    \"g_simulation\": [\"28\"],\n",
    "    \"g_webPublishing\": [\"59\"],\n",
    "    \"g_adventure\": [\"25\"],\n",
    "    \"g_gore\": [\"74\"],\n",
    "    \"g_sexual_content\": [\"71\"],\n",
    "    \"g_tutorial\": [\"84\"],\n",
    "    \"g_short\": [\"83\"],\n",
    "    \"g_photoEditing\": [\"55\"],\n",
    "    \"g_animationAndModeling\": [\"51\"],\n",
    "    \"g_360video\": [\"85\"],\n",
    "    \"g_gameDevelopment\": [\"60\"],\n",
    "    \"g_strategy\": [\"2\"],\n",
    "    \"g_indie\": [\"23\"],\n",
    "    \"g_movie\": [\"80\"],\n",
    "    \"g_violent\": [\"73\"],\n",
    "    \"g_accounting\": [\"50\"],\n",
    "    \"g_mmo\": [\"29\"],\n",
    "    \"g_sports\": [\"18\"],\n",
    "    \"g_education\": [\"54\"],\n",
    "    \"g_utilities\": [\"57\"],\n",
    "    \"g_episodic\": [\"82\"],\n",
    "    \"g_videoProduction\": [\"58\"],\n",
    "    \"g_rpg\": [\"3\"],\n",
    "    \"g_racing\": [\"9\"],\n",
    "    \"g_nudity\": [\"72\"],\n",
    "    \"g_casual\": [\"4\"],\n",
    "    \"g_ftp\": [\"37\"],\n",
    "    \"g_action\": [\"1\"],\n",
    "    \"g_audioProduction\": [\"52\"],\n",
    "    \"g_softwareTraining\": [\"56\"],\n",
    "    \"g_designAndIllustration\": [\"53\"],\n",
    "    \"g_documentary\": [\"81\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create columns for each category key \n",
    "for key in new_genres_dict.keys():\n",
    "    df2[key] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update value for columns depending on whther the id for that category is present for that row\n",
    "for index, row in df1.iterrows():\n",
    "    gen_list = row[\"genres\"]\n",
    "    if isinstance(gen_list, list):\n",
    "        for gen_dict in gen_list:\n",
    "            if isinstance(gen_dict, dict):\n",
    "                gen_id = gen_dict.get(\"id\")\n",
    "                for key, value in new_genres_dict.items():\n",
    "                   if gen_id in value:\n",
    "                        df2.loc[index, key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column with boolean with True for when this column is not null\n",
    "df2.loc[:,\"has_screenshots\"]  = df1.loc[:,\"screenshots\"].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column for recommendations with 0 as default\n",
    "df2[\"total_recommendations\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply literal eval\n",
    "df1[\"recommendations\"] = df1[\"recommendations\"].apply(lambda x: handle_literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get total recommendations from dictionary and add the value to the df column\n",
    "for index, row in df1.iterrows():\n",
    "    recommendations = row[\"recommendations\"]\n",
    "    if isinstance(recommendations, dict):\n",
    "        recommendation = recommendations.get(\"total\")\n",
    "        df2.loc[index, \"total_recommendations\"] = recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new columns\n",
    "df2[\"coming_soon\"] = False\n",
    "df2[\"release_date\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply literal eval\n",
    "df1[\"release_date\"] = df1[\"release_date\"].apply(lambda x: handle_literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dictionary values and add them to columns\n",
    "for index, row in df1.iterrows():\n",
    "    rdate_dict = row[\"release_date\"]\n",
    "    if isinstance(rdate_dict, dict):\n",
    "         df2.loc[index, \"release_date\"] = rdate_dict.get(\"date\")\n",
    "         df2.loc[index, \"coming_soon\"] = rdate_dict.get(\"coming_soon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make datetime value and then just turn to date without timestamp\n",
    "df2['release_date'] = pd.to_datetime(df2['release_date'], errors='coerce')\n",
    "df2['release_date'] = df2['release_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column with boolean for when this column is not null\n",
    "df2.loc[:,\"has_support_info\"]  = df1.loc[:,\"support_info\"].notna()\n",
    "df2.loc[:,\"has_background\"]  = df1.loc[:,\"background\"].notna()\n",
    "df2.loc[:,\"has_background_raw\"]  = df1.loc[:,\"background_raw\"].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create content descriptor boolean column using the dictionary\n",
    "for index, row in df1.iterrows():\n",
    "    c_dict = row[\"content_descriptors\"]\n",
    "    if isinstance(c_dict, dict):\n",
    "        if c_dict.get(\"notes\") is None:\n",
    "            df2.loc[index,\"has_content_warning\"] = False\n",
    "        else:\n",
    "            df2.loc[index,\"has_content_warning\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply literal eval\n",
    "df1[\"ratings\"] = df1[\"ratings\"].apply(lambda x: handle_literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for getting average required age from the ratings dictionary\n",
    "def average_required_age(row):\n",
    "    sum_age = 0\n",
    "    count = 0\n",
    "    rating_dict = row[\"ratings\"]  \n",
    "    if isinstance(rating_dict, dict):\n",
    "        for system_dict in rating_dict.values():\n",
    "            if \"required_age\" in system_dict:\n",
    "                try:\n",
    "                    required_age = int(system_dict[\"required_age\"])\n",
    "                    sum_age += required_age\n",
    "                    count += 1\n",
    "                except ValueError:\n",
    "                    pass\n",
    "    if count > 0:\n",
    "        average_age = sum_age / count\n",
    "    else:\n",
    "        average_age = 0\n",
    "    \n",
    "    return average_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for getting content descriptor from the ratings dictionary\n",
    "def get_content_warning(row):\n",
    "    rating_dict = row[\"ratings\"] \n",
    "    if isinstance(rating_dict, dict):\n",
    "        for system_dict in rating_dict.values():\n",
    "            if \"descriptors\" in system_dict:\n",
    "                a = system_dict.get(\"descriptors\")\n",
    "                if a != None and a != \"\":\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating the required age and content warning columns based on the rating dict\n",
    "for index, row in df2.iterrows():\n",
    "    if row[\"required_age\"] == 0:\n",
    "        df2.loc[index, \"required_age\"] = average_required_age(df1.loc[index])\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    if row[\"has_content_warning\"] == False:\n",
    "        df2.loc[index, \"has_content_warning\"] = get_content_warning(df1.loc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column with boolean with True for when this column is not null\n",
    "df2.loc[:,\"has_dlc\"]  = df1.loc[:,\"dlc\"].notna()\n",
    "df2.loc[:,\"has_movies\"]  = df1.loc[:,\"movies\"].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply literal eval\n",
    "df1[\"achievements\"] = df1[\"achievements\"].apply(lambda x: handle_literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column\n",
    "df2[\"total_achievements\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get total achievements from dictionary and update column\n",
    "for index, row in df1.iterrows():\n",
    "    achievements = row[\"achievements\"]\n",
    "    if isinstance(achievements, dict):\n",
    "        if \"total\" in achievements.keys():\n",
    "            total = achievements.get(\"total\")\n",
    "            df2.loc[index, \"total_achievements\"] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column with boolean with True for when this column is not null\n",
    "df2.loc[:,\"has_professional_reviews\"]  = df1.loc[:,\"reviews\"].notna()\n",
    "df2.loc[:,\"has_legal_notice\"]  = df1.loc[:,\"legal_notice\"].notna()\n",
    "df2.loc[:,\"has_drm_notice\"]  = df1.loc[:,\"drm_notice\"].notna()\n",
    "df2.loc[:,\"has_useraccount_notice\"]  = df1.loc[:,\"ext_user_account_notice\"].notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create functions to get the proportion positive, negative and the total reviews\n",
    "def proportion_positive(row):\n",
    "    pos = row[\"positive\"]\n",
    "    neg = row[\"negative\"]\n",
    "    if isinstance(pos, int) and isinstance(neg, int):\n",
    "        total = pos + neg\n",
    "        if total !=0:\n",
    "            result = pos/total\n",
    "            return result\n",
    "    return 0\n",
    "\n",
    "def proportion_negative(row):\n",
    "    pos = row[\"positive\"]\n",
    "    neg = row[\"negative\"]\n",
    "    if isinstance(pos, int) and isinstance(neg, int):\n",
    "        total = pos + neg\n",
    "        if total !=0:\n",
    "            result = neg/total\n",
    "            return result\n",
    "    return 0\n",
    "\n",
    "def total_reviews(row):\n",
    "    pos = row[\"positive\"]\n",
    "    neg = row[\"negative\"]\n",
    "    if isinstance(pos, int) and isinstance(neg, int):\n",
    "        total = pos + neg\n",
    "        return total\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new columns \n",
    "df2[\"reviews_proportion_positive\"] = 0\n",
    "df2[\"reviews_proportion_negative\"] = 0\n",
    "df2[\"total_user_reviews\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply functions to get values for these columns\n",
    "df2[\"reviews_proportion_positive\"] = df1.apply(proportion_positive, axis=1)\n",
    "df2[\"reviews_proportion_negative\"] = df1.apply(proportion_negative, axis=1)\n",
    "df2[\"total_user_reviews\"] = df1.apply(total_reviews, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to change the format for the owners range string\n",
    "def format_range(value):\n",
    "    parts = value.split(' .. ')\n",
    "    parts = [part.strip() for part in parts]\n",
    "    if len(parts) == 2:\n",
    "        return f'{parts[0]}-{parts[1]}'\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the new formatting to the df\n",
    "df2[\"owners\"] = df1[\"owners\"].apply(format_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to change the playtime in minutes to hours and the price in cents to dollars\n",
    "def playtime_hours(value):\n",
    "    if isinstance(value, int):\n",
    "        return value/60\n",
    "    return value\n",
    "\n",
    "def price_dollars(value):\n",
    "    if isinstance(value, float):\n",
    "        return value/100\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply functions and crate new columns\n",
    "df2[\"average_playtime\"] = df1[\"average_forever\"].apply(playtime_hours)\n",
    "df2[\"median_playtime\"] = df1[\"median_forever\"].apply(playtime_hours)\n",
    "df2[\"initial_price\"] = df1[\"initialprice\"].apply(price_dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply literal eval\n",
    "df1[\"tags\"] = df1[\"tags\"].apply(lambda x: handle_literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique tags \n",
    "tags = set()\n",
    "for index, row in df1.iterrows():\n",
    "    tags_dict = row[\"tags\"]\n",
    "    if isinstance(tags_dict, dict):\n",
    "        for key in tags_dict.keys():\n",
    "            tags.add(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create columns for each tag\n",
    "for tag in tags:\n",
    "    df2[f\"tag_{tag}\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the columns depending on whther that tag os stored in the dict for that row\n",
    "for index, row in df1.iterrows():\n",
    "    tags_dict = row[\"tags\"]\n",
    "    if isinstance(tags_dict, dict):\n",
    "        for key in tags_dict.keys():\n",
    "            df2.loc[index, f\"tag_{key}\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to get the proportion of recommendations\n",
    "def proportion_recommended(row):\n",
    "    rec = row[\"total_recommendations\"]\n",
    "    total = row[\"total_user_reviews\"]\n",
    "    if isinstance(rec, int) and isinstance(total, int):\n",
    "        if total !=0:\n",
    "            result = rec/total\n",
    "            return result\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column and apply function\n",
    "df2[\"proportion_recommended\"] = df1.apply(proportion_recommended, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Feature Reduction and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate a threshold that for 5% of data\n",
    "threshold = len(df2) * 0.05\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_columns = df2.columns[df2.dtypes == bool]\n",
    "drop_columns = [col for col in boolean_columns if df2[col].sum() <  threshold]\n",
    "print(len(drop_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get null counts\n",
    "null_counts = df2.isnull().sum()\n",
    "columns_null = null_counts[null_counts > 0]\n",
    "columns_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the highest value out of low medium high using the index for their position in the list\n",
    "def get_highest_value(row):\n",
    "    cols = ['Processor', 'Storage', 'Graphics', 'Memory']\n",
    "    values = []\n",
    "    for col in cols:\n",
    "        if pd.notnull(row[col]):\n",
    "            values.append(row[col])\n",
    "    if values:\n",
    "        highest_value = max(values, key=lambda x: ['Low', 'Medium', 'High'].index(x))\n",
    "        return highest_value\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new general system requirements colums applying the function to get the value for the hight requirement\n",
    "df2['system_reqs'] = df2.apply(get_highest_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make unknown category for null system reqs\n",
    "df2.loc[df2[\"system_reqs\"].isna(), 'system_reqs'] = \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the specific req columns\n",
    "cols_to_drop = ['Processor', 'Storage', 'Graphics', 'Memory']\n",
    "df2.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for rows where either developers or publishers is missing replace it with the value in the other\n",
    "df2['developers'] = df2['developers'].fillna(df2['publishers'])\n",
    "df2['publishers'] = df2['publishers'].fillna(df2['developers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the ones that still have missing values\n",
    "df2.dropna(subset=['developers'], inplace=True)\n",
    "df2.dropna(subset=['publishers'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop games with missing release date\n",
    "df2.dropna(subset=['release_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make initial price 0 if the game is free and has a missing intial price\n",
    "df2.loc[(df2[\"initial_price\"].isna()) & (df2[\"is_free\"] == True), \"initial_price\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the ones that still had intial price\n",
    "df2.dropna(subset=['initial_price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling age outliers by assigning mac not extreme age of 21 when the game has a content warning and 0 otherwise\n",
    "df2.loc[(df2[\"required_age\"] > 21) & (df2[\"has_content_warning\"] ==True), \"required_age\"] = 21\n",
    "df2.loc[(df2[\"required_age\"] > 21), \"required_age\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3 - Prepare data for use in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranform datatypes\n",
    "df2[\"steam_appid\"] = df2[\"steam_appid\"].astype(int)\n",
    "df2[\"required_age\"] = df2[\"required_age\"].astype(int)\n",
    "df2[\"publishers\"] = df2['publishers'].astype('category')\n",
    "df2[\"developers\"] = df2['developers'].astype('category')\n",
    "df2[\"system_reqs\"] = df2['system_reqs'].astype('category')\n",
    "df2[\"owners\"] = df2['owners'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split date data\n",
    "df2['release_month'] = df2['release_date'].dt.month\n",
    "df2['release_year'] = df2['release_date'].dt.year\n",
    "df2['release_day_of_week'] = df2['release_date'].dt.dayofweek\n",
    "df2['release_day_of_month'] = df2['release_date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count values in classes of owners\n",
    "class_counts = df2['owners'].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the three highest categories into one\n",
    "df2.loc[(df2[\"owners\"] == \"50,000,000-100,000,000\")|\n",
    " (df2[\"owners\"] == \"200,000,000-500,000,000\")|\n",
    "  (df2[\"owners\"] == \"100,000,000-200,000,000\"), \"owners\"] = \"50,000,000+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict to map system req cats\n",
    "system_reqs_map = {\n",
    "    3: 'High', 1: 'Low', 2: 'Medium', 0: 'Unknown'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict to map owner cats\n",
    "owners_map = {\n",
    " 1: '0-20,000',\n",
    " 7: '1,000,000-2,000,000',\n",
    " 10: '10,000,000-20,000,000',\n",
    " 4: '100,000-200,000',\n",
    " 8: '2,000,000-5,000,000',\n",
    " 11: '20,000,000-50,000,000',\n",
    " 2: '20,000-50,000',\n",
    " 5: '200,000-500,000',\n",
    " 9: '5,000,000-10,000,000',\n",
    " 12: '50,000,000+',\n",
    " 3: '50,000-100,000',\n",
    " 6: '500,000-1,000,000'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_day_of_week_map = {\n",
    " 5: 'Friday',\n",
    " 1: 'Monday',\n",
    " 6: 'Saturday',\n",
    " 7: 'Sunday',\n",
    " 4: 'Thursday',\n",
    " 2: 'Tuesday',\n",
    " 3: 'Wednesday'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dict with category and catehgory code\n",
    "publishers_map = {\n",
    "    code: category\n",
    "    for code, category in enumerate(df2['publishers'].astype('category').cat.categories)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dict with category and catehgory code\n",
    "developers_map = {\n",
    "    code: category\n",
    "    for code, category in enumerate(df2['developers'].astype('category').cat.categories)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to reverse the key values in the dict\n",
    "def reverse_dict(dictionary):\n",
    "    dictionary = {v: k for k, v in dictionary.items()}\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply reverse dict function\n",
    "release_day_of_week_map = reverse_dict(release_day_of_week_map)\n",
    "owners_map = reverse_dict(owners_map)\n",
    "system_reqs_map = reverse_dict(system_reqs_map)\n",
    "developers_map = reverse_dict(developers_map)\n",
    "publishers_map = reverse_dict(publishers_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create colums for the cat codes using dictionary mapping\n",
    "df1['release_day_of_week_code'] = df1['release_day_of_week'].map(release_day_of_week_map)\n",
    "df1[\"owners_code\"] = df1['owners'].map(owners_map)\n",
    "df1[\"system_reqs_code\"] = df1['system_reqs'].map(system_reqs_map)\n",
    "df1[\"developers_code\"] = df1['developers'].map(developers_map)\n",
    "df1[\"publishers_code\"] = df1['publishers'].map(publishers_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bins and labels for making proprotion of postive reviews categories\n",
    "bins = [-0.001, 0.2, 0.4, 0.6, 0.8, 1.001]\n",
    "labels = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the categories with codes for the review proportion positive\n",
    "df2[\"reviews_proportion_positive_bin_code\"] = pd.cut(df1['reviews_proportion_positive'], bins=bins, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "df2.to_csv(\"clean_data_with_codes.csv\", index = 'False')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
